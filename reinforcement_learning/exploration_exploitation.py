import random
import matplotlib.pyplot as plt

# Definindo a configuração do agente
rounds = 50 # X rounds do agente
hist_points = [] # Histórico dos pontos em cada rodada
choices = [] # Histórico de escolhas

# Porta A tem baixa variabilidade, com resultados mais sólidos entre 8 e 12
def reward_door_a():
    return random.randint(8, 12)

# Porta B tem alta variabilidade, com resultados mais altos de 0 ou 100
def reward_door_b():
    return random.choice([0, 100])

# Exploração inicial
explorer_door_b = False

# Execução do "Modelo"
for round in range(1, rounds + 1):
  print(f"\nRodada {round + 1}")

  # Forçamos a primeira exploração obrigatória na porta B
  if not explorer_door_b:
    print("Exploração: tentando na porta B")
    explorer_door_b = True
    door = "B"
    reward = reward_door_b()
  else:
    # Após a primeira vez a porta A é preferida por segurança
    # Mas com 10% de chance de tentar a porta B novamente
    if random.random() < 0.1:
      print("Exploração: tentando na porta B")
      door = "B"
      reward = reward_door_b()
    else:
      print("Exploração: Garantindo na porta A")
      door = "A"
      reward = reward_door_a()


  print(f"Porta escolhida: {door} | pontos ganhos: {reward}")
  hist_points.append(reward)
  choices.append(door)

  # Visualização do caminho do agente
plt.figure(figsize=(12, 6))
plt.plot(hist_points, marker='o')
plt.xlabel('Rodada')
plt.ylabel('Pontos')
plt.title('Pontuação do agente')
plt.grid(True)
plt.show()

# Resumo das escolhas
print("\nResumo das escolhas:")
print(f"Portas A: {choices.count('A')} vezes")
print(f"Portas B: {choices.count('B')} vezes")
print(f"Total de pontos: {sum(hist_points)}")